{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pybrain.structure.modules import LSTMLayer, SoftmaxLayer\n",
    "from pybrain.supervised import RPropMinusTrainer\n",
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.datasets import SequenceClassificationDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import scipy.io.wavfile as wav\n",
    "from __future__ import division\n",
    "import math\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "\n",
    "chunk_size = 100\n",
    "\n",
    "segments = []\n",
    "\n",
    "path = \"calls\"\n",
    "c_total = 0\n",
    "c_read = 0\n",
    "c_skipped = 0\n",
    "audio_files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "for audio_file in audio_files[0:100]:\n",
    "    c_total+=1\n",
    "    print \"Reading file: \"+str(c_total)\n",
    "    try:\n",
    "        rate_sig, sig = wav.read(join(path, audio_file))\n",
    "        c_read+=1\n",
    "    except:\n",
    "        c_skipped+=1\n",
    "        continue\n",
    "    for i in range(int(math.ceil(len(sig)/(chunk_size)))):\n",
    "        chunk = sig[i*(chunk_size):i*(chunk_size) + chunk_size]\n",
    "        if(len(chunk) < chunk_size):\n",
    "            np.append(chunk,([0 for i in range(chunk_size-len(chunk))]))\n",
    "        else:    \n",
    "            segments.append(chunk)\n",
    "print \"\\n\\n\"\n",
    "print \"Total files: \"+str(c_total)\n",
    "print \"Read files: \"+str(c_read)\n",
    "print \"Skipped files:\"+str(c_skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = SequenceClassificationDataSet(chunk_size, chunk_size)\n",
    "print \"Total Segments = \"+str(len(segments))+\".\"\n",
    "for i in range(4000):\n",
    "    print \"Adding segment: \"+str(i)+\" with: \"+str((i+1)%len(segments))+\".\"\n",
    "    dataset.addSample(segments[i], segments[(i+1)%len(segments)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn = buildNetwork(dataset.indim, 20, dataset.outdim, hiddenclass = LSTMLayer, outclass = SoftmaxLayer, outputbias = False, recurrent = True)\n",
    "trainer = RPropMinusTrainer(rnn, dataset = dataset, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for train_count in range(5):\n",
    "    trainer.trainEpochs(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generated_audio_samples = []\n",
    "generated_audio_samples.append(segments[np.random.randint(0, len(segments), size = 1)])\n",
    "for i in range(1):\n",
    "    print rnn.activate(generated_audio_samples[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
